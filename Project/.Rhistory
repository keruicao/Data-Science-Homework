c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")
c2 = ggplot(c,aes(y = gender1,x = gender2,fill = prop)) + geom_tile()+ geom_tile()+geom_text(aes(label = round(prop,2))) +
scale_fill_gradient(low = "white", high = "red")  + theme(legend.position = "top")
gridExtra::grid.arrange(c1,c2,ncol=2)
c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")
c2 = ggplot(c,aes(y = gender1,x = gender2,fill = prop)) + geom_tile()+ geom_tile()+geom_text(aes(label = round(prop,2))) +
scale_fill_gradient(low = "white", high = "red")  + theme(legend.position = "")
gridExtra::grid.arrange(c1,c2,ncol=2)
library(AER)
data("Fertility")
daa = Fertility
c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")
c2 = ggplot(c,aes(y = gender1,x = gender2,fill = prop)) + geom_tile()+ geom_tile()+geom_text(aes(label = round(prop,2))) +
scale_fill_gradient(low = "white", high = "red")  + theme(legend.position = "")
gridExtra::grid.arrange(c1,c2,ncol=2)
library(AER)
data("Fertility")
daa = Fertility
c29 = daa %>% filter(age>29) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c29$"prop" = c$count/sum(c$count)
c30 = daa %>% filter(age>30) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c30$"prop" = c$count/sum(c$count)
View(c29)
View(c30)
View(c2)
View(c30)
View(c29)
View(c30)
c29 = daa %>% filter(age>29) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c29$"prop" = c$count/sum(c$count)
c30 = daa %>% filter(age>30) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c30$"prop" = c$count/sum(c$count)
cc29 = ggplot(c29,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")
cc30 = ggplot(c30,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")
gridExtra::grid.arrange(cc29,cc30,ncol=2)
c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")
c2 = ggplot(c,aes(y = gender1,x = gender2,fill = prop)) + geom_tile()+ geom_tile()+geom_text(aes(label = round(prop,2))) +
scale_fill_gradient(low = "white", high = "red")  + theme(legend.position = "")
gridExtra::grid.arrange(c1,c2,ncol=2)
c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "") + ggtitle("Counts for four combinations")
c2 = ggplot(c,aes(y = gender1,x = gender2,fill = prop)) + geom_tile()+ geom_tile()+geom_text(aes(label = round(prop,2))) +
scale_fill_gradient(low = "white", high = "red")  + theme(legend.position = "")+ ggtitle("Proportion for four combinations")
gridExtra::grid.arrange(c1,c2,ncol=2)
c29 = daa %>% filter(age>29) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c29$"prop" = c$count/sum(c$count)
c30 = daa %>% filter(age>30) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c30$"prop" = c$count/sum(c$count)
cc29 = ggplot(c29,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")+ ggtitle("before 30")
cc30 = ggplot(c30,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")+ ggtitle("after 30")
gridExtra::grid.arrange(cc29,cc30,ncol=2)
c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "") + ggtitle("Counts for four combinations")
c2 = ggplot(c,aes(y = gender1,x = gender2,fill = prop)) + geom_tile()+ geom_tile()+geom_text(aes(label = round(prop,2))) +
scale_fill_gradient(low = "white", high = "red")  + theme(legend.position = "")+ ggtitle("Proportion for four combinations")
gridExtra::grid.arrange(c1,c2,ncol=2)
c = daa %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c$"prop" = c$count/sum(c$count)
c1 = ggplot(c,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "") + ggtitle("Counts for four combinations",align = "c")
c29 = daa %>% filter(age>29) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c29$"prop" = c$count/sum(c$count)
c30 = daa %>% filter(age>30) %>% group_by(gender1,gender2) %>% summarise(count = length(age))
c30$"prop" = c$count/sum(c$count)
cc29 = ggplot(c29,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")+ ggtitle("Age before 30")
cc30 = ggplot(c30,aes(y = gender1,x = gender2,fill = count)) + geom_tile()+geom_text(aes(label = count)) +
scale_fill_gradient(low = "white", high = "red") + theme(legend.position = "")+ ggtitle("Age after 30")
gridExtra::grid.arrange(cc29,cc30,ncol=2)
e = daa %>% group_by(afarm,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
View(e)
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"ethnicity" = c("Caucasian","None","hispanish","African-American")
esquisse::esquisser(e)
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"ethnicity" = c("Caucasian","None","hispanish","African-American")
library(ggplot2)
ggplot(e) +
aes(x = ethnicity, weight = count) +
geom_bar(fill = "#0c4c8a") +
theme_minimal()
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"ethnicity" = c("Caucasian","None","hispanish","African-American")
e %<>% mutate(frequency = count/sum(count))
library(ggplot2)
ggplot(e) +
aes(x = ethnicity, weight = frequency) +
geom_bar(fill = "#0c4c8a") +
theme_minimal()
View(e)
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"ethnicity" = c("Caucasian","None","hispanish","African-American")
e$"frequency" = e$count/sum(e$count)
library(ggplot2)
ggplot(e) +
aes(x = ethnicity, weight = frequency) +
geom_bar(fill = "#0c4c8a") +
theme_minimal()
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"ethnicity" = c("Caucasian","None","hispanish","African-American")
e$"frequency" = e$count/sum(e$count)
library(ggplot2)
ggplot(e) +
aes(x = ethnicity, weight = frequency) +
geom_bar(fill = "#0c4c8a") +
theme_minimal() + ylab("frequency")
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"ethnicity" = c("Caucasian","None","hispanish","African-American")
e$"frequency" = e$count/sum(e$count)
library(ggplot2)
ggplot(e) +
aes(x = ethnicity, weight = frequency) +
geom_bar(fill = "#0c4c8a") +
theme_minimal() + ylab("frequency of having more than two kids")
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"Ethnicity" = c("Caucasian","None","hispanish","African-American")
e$"frequency" = e$count/sum(e$count)
library(ggplot2)
ggplot(e) +
aes(x = ethnicity, weight = frequency) +
geom_bar(fill = "#0c4c8a") +
theme_minimal() + ylab("Frequency of having more than two kids")
e = daa %>% group_by(afam,hispanic,other) %>% summarise(count=sum(morekids=="no"))
e = e[c(1,2,3,5),]
e$"Ethnicity" = c("Caucasian","None","hispanish","African-American")
e$"frequency" = e$count/sum(e$count)
library(ggplot2)
ggplot(e) +
aes(x = Ethnicity, weight = frequency) +
geom_bar(fill = "#0c4c8a") +
theme_minimal() + ylab("Frequency of having more than two kids")
data("mtcars")
force(mtcars)
View(mtcars)
rownames(mtcars)
contains(rownames(mtcars),"e")
rownames(mtcars) %contains% "e"
library(data.table)
rownames(mtcars) %contains% "e"
"e" %in% rownames(mtcars)
apply(rownames(mtcars), 2,function(x){"e" %in% x})
mtcars
class(rownames(mtcars))
rownames()
rownames(mtcars)
rr =rownames(mtcars)
rr[1]
br = c(16,9,10,13,19,20,18,17,35,55)
vr = c(58,90,48,57,103,20,57,86,112,273,64)
vr = c(58,90,48,57,103,57,86,112,273,64)
br = c(16,9,10,13,19,20,18,17,35,55)
vr = c(58,90,48,57,103,57,86,112,273,64)
sum(br)
sum(vr)
sr = rbeta(1000,shape1 = 213,shape2 = 949)
hist(sr)
hist(sr,breaks = 100)
curve(dbeta(shape1 = 213,shape2 = 949),from = 0.05,to = 0.27)
curve(dbeta(x,shape1 = 213,shape2 = 949),from = 0.05,to = 0.27)
hist(sr,breaks = 100)
curve(dbeta(x,shape1 = 213,shape2 = 949),from = 0.05,to = 0.27)
plot(t, dbeta(t, sum(x)+alpha, beta + m*n-sum(x)), type = "l",
xlab = expression(theta), ylab = "density")
lines(t, dnorm(t, mod, sd), lty = 2)
n=30 # sample size (# of experiment)
m=5  # number of trials in each experiment
alpha = 1
beta = 0
#theta = rbeta(1,alpha,beta)
x = rbinom(n,m,0.75) # observations
mod = (mean(x)+(alpha-1)/n)/(m+(alpha+beta-2)/n)
I.theta = (sum(x)+alpha-1)/(mod^2)+(m*n+beta-sum(x)-1)/((1-mod)^2)
sd = sqrt(1/I.theta)
t = seq(0.5,1,0.0005)
plot(t, dbeta(t, sum(x)+alpha, beta + m*n-sum(x)), type = "l",
xlab = expression(theta), ylab = "density")
lines(t, dnorm(t, mod, sd), lty = 2)
line(t,dbeta(t,shape1 = 213,shape2 = 949))
line(t,dbeta(t,shape1 = 213,shape2 = 949))
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
hist(sr,breaks = 100)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
hist(sr,breaks = 100)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
# [ Prior Elicitation ]
# assume conjugacy: theta ~ Gamma(alpha, beta)
# "on average, 4 cars per hour" -> E[theta] = alpha / beta = 4
# "most likely between 1 to 6 cars per hour" -> P(1 <= theta <= 6) = .95
# find beta numerically by finding an approximate root to 'f'
f <- function (beta)
pgamma(6, 4 * beta, beta) - pgamma(1, 4 * beta, beta) - .95
beta <- round(uniroot(f, lower = 0, upper = 10)$root, 0)
b <- seq(0, 10, length = 100)
plot(b, f(b), type = "l")
abline(h = 0, lty = 2); abline(v = beta)
alpha <- 4 * beta
# [ Bayesian Analysis ]
# data:
x <- c(1, 2, 4); y <- c(2, 4, 16)
# check posterior graphically
t <- seq(0, 8, length = 100) # theta
plot(t, dgamma(t, alpha + sum(y), beta + sum(x)),
type = "l", xlab = expression(theta), ylab = "density")
# 95% credible interval
qgamma(c(.025, .975), alpha + sum(y), beta + sum(x))
# describing posterior by sampling:
ns <- 1000 # #samples
ts <- rgamma(ns, alpha + sum(y), beta + sum(x))
hist(ts, prob = TRUE)
lines(t, dgamma(t, alpha + sum(y), beta + sum(x)))
hist(sr,breaks = 100,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
theta_r = rbeta(1000,shape1 = 213,shape2 = 949)
hist(sr,breaks = 100,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
theta_r = rbeta(1000,shape1 = 213,shape2 = 949)
hist(theta_r,breaks = 100,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
hist(theta_r,breaks = 50,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
bn = c(12,1,2,4,9,7,9,8)
8
bn = c(12,1,2,4,9,7,9,8)
vn = c(113,18,14,44,208,67,29,154)
sum(bn)
sum(vn)
theta_r = rbeta(1000,shape1 = 53,shape2 = 648)
hist(theta_r,breaks = 50,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 53,shape2 = 648))
theta_r = rbeta(1000,shape1 = 213,shape2 = 949)
hist(theta_r,breaks = 50,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 213,shape2 = 949))
theta_r = rbeta(1000,shape1 = 53,shape2 = 648)
hist(theta_r,breaks = 50,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 53,shape2 = 648))
theta_n = rbeta(1000,shape1 = 53,shape2 = 648)
hist(theta_n,breaks = 50,probability = T)
t = seq(0.05,0.27,0.001)
lines(t,dbeta(t,shape1 = 53,shape2 = 648))
diff = theta_r-theta_n
hist(diff)
hist(diff,probability = T, breaks = 50)
library(rattle)
install.packages("rattle")
library(rattle)
library(esquisse)
data("wine")
da = data("wine")
force(wine)
da = data(wine)
force(wine)
View(wine)
View(wine)
da = wine
funModeling::data_integrity(da)
esquisser(da)
plot(da)
hist(da)
rattle()
install.packages("RGtk2")
rattle()
rattle()
cor = cor(da)
corrplot()
install.packages("corrplot")
corrplot(corr = cor,method = "squared")
corrplot(cor,method = "squared")
library(rattle)
library(corrplot)
corrplot(cor,method = "squared")
corrplot(cor,method = "square")
cor = cor(da)
corrplot(cor,method = "square")
cor = cor(da)
View(da)
da = da[-"type"]
library(tidyverse)
da = select(da,-type)
da = select(da,-'type')
da = select(da,-'Type')
cor = cor(da)
corrplot(cor,method = "square")
wine_3 = kmeans(da, 3)
print(wine_3)
confusion_matrix = table(da[,1],wine_3$cluster)
confusion_matrix
confusion_matrix = table(wine[,1],wine_3$cluster)
confusion_matrix
perc_corect = sum(diag(confusion_matrix))/sum(confusion_matrix)
perc_corect
wine_3 = kmeans(da, 3)
print(wine_3)
confusion_matrix = table(wine[,1],wine_3$cluster)
confusion_matrix
perc_corect = sum(diag(confusion_matrix))/sum(confusion_matrix)
perc_corect
wine_3 = kmeans(da, 3)
print(wine_3)
confusion_matrix = table(wine[,1],wine_3$cluster)
confusion_matrix
perc_corect = sum(diag(confusion_matrix))/sum(confusion_matrix)
perc_corect
library(cluster)
clusplot(da,wine_3,main = "lol", color = T, shade = T, labels = 2, lines = 0)
clusplot(da,wine_3$cluster,main = "lol", color = T, shade = T, labels = 2, lines = 0)
## Hierachical cluster
d = dist(da,method = "ecuclidean")
## Hierachical cluster
d = dist(da,method = "euclidean")
H.fit = hclust(d,method = "ward")
plot(H.fit)
setwd("D:/R-connect-Server/DataScience in R/Project")
WV_RD <- readRDS("survey_data.rds")
library(tidyverse)
library(magrittr)
da = WV_RD
da %<>% select(V1:V250)
da = data.frame(apply(da,MARGIN = 2,function(x){x = ifelse(x<0, NA, x)}))
# Calculate the NA value of each variables
NA_NUM = data.frame(da %>% apply(MARGIN = 2,function(x){round(sum(is.na(x))/length(x),2)}))
NA_NUM["name"] = rownames(NA_NUM)
colnames(NA_NUM) = c("Prop","name")
# The distribution of NA of each variables
hist(NA_NUM$Prop,breaks = 20)
# delete variables with nore than 10% NA
NA_NUM %<>% filter(Prop<=0.1)
da %<>% select(NA_NUM[,2])
# V1,V2A,V3 are code for questionaire
da %<>% select(-V1,-V2A,-V3)
#delete NA observations
da = na.omit(da)
cor = cor(da[,2:215])
# calculate the unique value of each variables.
ui = data.frame(da %>% apply(MARGIN = 2,function(x){unique(x)%>%length}))
da %<>% select(-V125_16,-V125_17)
cor = cor(da[,2:213])
cor_c = reshape2::melt(cor)
hist(cor_c$value,breaks = 1000)
car::qqPlot(cor_c$value,id=F)
## Cross Comparison
da %>% filter(V2==51) %>% with(table(V4,V5))
col = function(x){
xf = factor(x)
xr = tapply(x, xf, length)/length(x)
return(xr)
}
da %>% filter(V2 == 51) %>% with(col(V4))
sa = sample(18445,replace = F,size = 1000)
das = da[sa,]
dasa = da[sa,]
# transfer binary variables into factors:
ui["name"] = rownames(ui)
colnames(ui) = c("Uni_value","name")
cat = ui$name[which(ui$Uni_value==2)]
for(i in cat){
das[i] = as.factor(as.matrix(das[i]))
}
# Calculate Correlation matrix
library(polycor)
cormat = hetcor(das[,2:213])$cor
cormat_c = reshape2::melt(cormat)
hist(cormat_c$value,breaks = 1000)
View(cormat)
View(cormat_c)
View(cormat_c)
is.na(cormat_c)
sum(is.na(cormat_c$value))
car::qqPlot(cormat_c$value,id=F)
# calculate Factor
library(psych)
wls.fa = fa(r = cormat,nfactors = 40,rotate = "varimax", fm = "wls")
gls.fa = fa(r = cormat,nfactors = 20,rotate = "varimax", fm = "gls")
pa.fa = fa(r = cormat,nfactors = 20,rotate = "varimax", fm = "pa")
mle.fa = fa(r = cormat,nfactors = 20,rotate = "varimax", fm = "ml")
# Calculate the principal components
lo = matrix(nrow = 212,ncol = 20)
va = as.matrix(dasa[,2:213])
for(i in 1 : 212){
for(j in 1:20){
lo[i,j] = mle.fa$loadings[i,j]
}
}
dasa = data.frame(cbind(dasa[,1],va %*% lo))
View(dasa)
View(das)
library(cluster)
m=10 # number of clusters
n=10  # number of repeats experiments for each number of clusters
dasc = dasa[-1]
tot = matrix(nrow = m,ncol  = n)
f = matrix(nrow = m,ncol  = n)
for(i in 1:m){
for(j in 1:n){
cl = kmeans(x = test1,centers = i)
f[i,j] = cl$betweenss/cl$tot.withinss
tot[i,j] = cl$tot.withinss
}
}
tot %<>% apply(MARGIN = 1,mean)
for(i in 1:m){
for(j in 1:n){
cl = kmeans(x = dasc,centers = i)
f[i,j] = cl$betweenss/cl$tot.withinss
tot[i,j] = cl$tot.withinss
}
}
m=10 # number of clusters
n=10  # number of repeats experiments for each number of clusters
tot = matrix(nrow = m,ncol  = n)
f = matrix(nrow = m,ncol  = n)
for(i in 1:m){
for(j in 1:n){
cl = kmeans(x = dasc,centers = i)
f[i,j] = cl$betweenss/cl$tot.withinss
tot[i,j] = cl$tot.withinss
}
}
for(i in 1:m){
for(j in 1:n){
cl = kmeans(x = dasc,centers = i)
f[i,j] = cl$betweenss/cl$tot.withinss
tot[i,j] = cl$tot.withinss
}
}
tot %<>% apply(MARGIN = 1,mean)
f %<>% apply(MARGIN = 1,mean)
plot(tot,type = "l")
plot(f,type = "l")
# choose number of clusters 3
best = NULL
toot = 5096960434
for(i in 1:100){
cl = kmeans(test,4)
if (cl$tot.withinss<toot) {
toot = cl$tot.withinss
best = cl$cluster
}
}
# choose number of clusters 3
best = NULL
toot = 5096960434
for(i in 1:100){
cl = kmeans(dasc,4)
if (cl$tot.withinss<toot) {
toot = cl$tot.withinss
best = cl$cluster
}
}
toot
das["cluster"]=best
das$cluster
tot
2.146540e+12
# choose number of clusters 3
best = NULL
toot = 2.146540e+12
for(i in 1:100){
cl = kmeans(dasc,4)
if (cl$tot.withinss<toot) {
toot = cl$tot.withinss
best = cl$cluster
}
}
toot
das["cluster"]=best
das$cluster
cl_for_each_country = test %>% group_by(country) %>% summarise(num_of_c1 = sum(V10==1),num_of_c2 = sum(V10==2),num_of_c3 = sum(V10==3))
cl_for_each_country = das %>% group_by(X1) %>% summarise(num_of_c1 = sum(cluster==1),num_of_c2 = sum(cluster==2),num_of_c3 = sum(cluster==3))
cl_for_each_country = das %>% group_by(V2) %>% summarise(num_of_c1 = sum(cluster==1),num_of_c2 = sum(cluster==2),num_of_c3 = sum(cluster==3))
cl_for_each_country %>% arrange(desc(num_of_c1)) %>% head
cl_for_each_country %>% arrange(desc(num_of_c2)) %>% head
cl_for_each_country %>% arrange(desc(num_of_c3)) %>% head
